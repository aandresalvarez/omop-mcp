# ============================================================================
# OMOP MCP Server - Environment Configuration
# ============================================================================
# Copy this file to .env and customize for your environment
# All values shown are examples - replace with your actual configuration

# ============================================================================
# REQUIRED: OpenAI API Key
# ============================================================================
# Required for PydanticAI agents (concept discovery, SQL generation)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Optional: OpenAI model configuration
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.0

# ============================================================================
# REQUIRED: Database Backend Selection
# ============================================================================
# Choose one backend: "duckdb", "bigquery", "snowflake", "postgres"
BACKEND_TYPE=duckdb

# ============================================================================
# DuckDB Configuration (Local Development)
# ============================================================================
# DuckDB is included in core dependencies - no additional setup needed!
# Perfect for local development, testing, and small datasets

# Database file path (use :memory: for in-memory database)
DUCKDB_DATABASE_PATH=:memory:
# Alternative: persistent file
# DUCKDB_DATABASE_PATH=./omop_data.duckdb

# Schema name (usually "main")
DUCKDB_SCHEMA=main

# ============================================================================
# BigQuery Configuration (Google Cloud Platform)
# ============================================================================
# For cloud-scale analytics and production deployments

# Google Cloud Project ID
BIGQUERY_PROJECT_ID=your-gcp-project-id

# OMOP CDM dataset ID
BIGQUERY_DATASET_ID=omop_cdm

# Service account credentials file path
BIGQUERY_CREDENTIALS_PATH=/path/to/service-account.json

# Alternative: Use Application Default Credentials (ADC)
# BIGQUERY_CREDENTIALS_PATH=  # Leave empty to use ADC
#
# ADC Authentication Methods:
# 1. User credentials (development):
#    gcloud auth application-default login
#
# 2. Service account via environment variable:
#    export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
#
# 3. Metadata service (GCP environments - Cloud Run, Compute Engine, etc.):
#    Automatically available - no additional setup needed
#
# 4. Workload Identity (Kubernetes):
#    Configured via service account annotations

# BigQuery location (US, EU, etc.)
BIGQUERY_LOCATION=US

# ============================================================================
# Snowflake Configuration (Enterprise Data Warehouse)
# ============================================================================
# For enterprise-scale analytics and production deployments

# Snowflake account URL
SNOWFLAKE_ACCOUNT=your-account.snowflakecomputing.com

# Authentication credentials
SNOWFLAKE_USER=your_username
SNOWFLAKE_PASSWORD=your_password

# Alternative: Use key-pair authentication
# SNOWFLAKE_PRIVATE_KEY_PATH=/path/to/private_key.p8
# SNOWFLAKE_PRIVATE_KEY_PASSPHRASE=your_passphrase

# Database and schema
SNOWFLAKE_DATABASE=omop_db
SNOWFLAKE_SCHEMA=cdm

# Warehouse for compute
SNOWFLAKE_WAREHOUSE=compute_wh

# Role (optional)
SNOWFLAKE_ROLE=omop_analyst

# ============================================================================
# PostgreSQL Configuration (Future Support)
# ============================================================================
# For traditional relational database deployments

# PostgreSQL connection string
POSTGRES_DSN=postgresql://username:password@hostname:5432/database_name

# Alternative: Individual components
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DB=omop_cdm
# POSTGRES_USER=omop_user
# POSTGRES_PASSWORD=your_password

# Schema name
POSTGRES_SCHEMA=public

# Connection pool settings
POSTGRES_POOL_SIZE=10
POSTGRES_POOL_TIMEOUT=30

# ============================================================================
# ATHENA API Configuration
# ============================================================================
# ATHENA is the public OMOP vocabulary API - no authentication required

# Base URL for ATHENA API
ATHENA_BASE_URL=https://athena.ohdsi.org/api/v1

# Request timeout in seconds
ATHENA_TIMEOUT=30

# ============================================================================
# Security & Access Control
# ============================================================================

# Maximum query cost in USD (BigQuery only)
MAX_COST_USD=1.0

# Allow patient ID queries (set to false in production)
ALLOW_PATIENT_LIST=false

# Query timeout in seconds
QUERY_TIMEOUT_SEC=30

# Enable PHI mode (development only - allows access to PHI columns)
PHI_MODE=false

# ============================================================================
# SQL Validation & Security
# ============================================================================

# Enable strict OMOP table allowlist validation
STRICT_TABLE_VALIDATION=false

# Custom allowed tables (comma-separated)
OMOP_ALLOWED_TABLES=person,condition_occurrence,drug_exposure,procedure_occurrence,measurement,observation,visit_occurrence,death,concept,vocabulary,concept_relationship,concept_ancestor

# Blocked PHI columns (comma-separated)
OMOP_BLOCKED_COLUMNS=person_source_value,provider_source_value,location_source_value,care_site_source_value

# ============================================================================
# OAuth 2.1 Authentication (Production)
# ============================================================================
# Enable for production deployments with authentication

# OAuth issuer URL
OAUTH_ISSUER=https://your-auth-provider.com

# OAuth audience
OAUTH_AUDIENCE=omop-mcp-api

# ============================================================================
# Agent Configuration
# ============================================================================
# Settings for PydanticAI agents

# Maximum concepts per query
MAX_CONCEPTS_PER_QUERY=50

# Top K results for concept search
CONCEPT_SEARCH_TOP_K=10

# Time limit per query in seconds
PER_QUERY_TIME_LIMIT_SEC=60

# Maximum retries for failed requests
MAX_RETRIES=3

# ============================================================================
# Server Configuration
# ============================================================================

# HTTP server host (for HTTP mode)
HTTP_HOST=0.0.0.0

# HTTP server port (for HTTP mode)
HTTP_PORT=8000

# Enable HTTPS (requires SSL certificates)
HTTPS_ENABLED=false
SSL_CERT_PATH=./cert.pem
SSL_KEY_PATH=./key.pem

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:3080

# ============================================================================
# Logging & Monitoring
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Enable structured logging
STRUCTURED_LOGGING=true

# Log file path (optional)
LOG_FILE_PATH=./logs/omop-mcp.log

# ============================================================================
# Performance & Caching
# ============================================================================

# Enable query result caching
ENABLE_QUERY_CACHE=true

# Cache TTL in seconds
QUERY_CACHE_TTL=3600

# Database connection pool size
DATABASE_POOL_SIZE=10

# Database connection timeout
DATABASE_POOL_TIMEOUT=30

# ============================================================================
# Development & Testing
# ============================================================================

# Enable debug mode
DEBUG=false

# Enable verbose logging
VERBOSE_DEBUG=false

# Test database path (for testing)
TEST_DATABASE_PATH=:memory:

# Mock external APIs in tests
MOCK_EXTERNAL_APIS=false

# ============================================================================
# Example Configurations
# ============================================================================

# ============================================================================
# Local Development (DuckDB)
# ============================================================================
# BACKEND_TYPE=duckdb
# DUCKDB_DATABASE_PATH=:memory:
# OPENAI_API_KEY=sk-your-key-here
# MAX_COST_USD=10.0
# ALLOW_PATIENT_LIST=true
# LOG_LEVEL=DEBUG

# ============================================================================
# Production BigQuery
# ============================================================================
# BACKEND_TYPE=bigquery
# BIGQUERY_PROJECT_ID=your-production-project
# BIGQUERY_DATASET_ID=omop_cdm_prod
# BIGQUERY_CREDENTIALS_PATH=/secrets/service-account.json
# OPENAI_API_KEY=sk-your-key-here
# MAX_COST_USD=1.0
# ALLOW_PATIENT_LIST=false
# STRICT_TABLE_VALIDATION=true
# OAUTH_ISSUER=https://your-auth-provider.com
# OAUTH_AUDIENCE=omop-mcp-api
# LOG_LEVEL=INFO

# ============================================================================
# Enterprise Snowflake
# ============================================================================
# BACKEND_TYPE=snowflake
# SNOWFLAKE_ACCOUNT=your-account.snowflakecomputing.com
# SNOWFLAKE_USER=omop_analyst
# SNOWFLAKE_PASSWORD=your-secure-password
# SNOWFLAKE_DATABASE=omop_warehouse
# SNOWFLAKE_SCHEMA=cdm_v5
# SNOWFLAKE_WAREHOUSE=analytics_wh
# OPENAI_API_KEY=sk-your-key-here
# MAX_COST_USD=5.0
# ALLOW_PATIENT_LIST=false
# STRICT_TABLE_VALIDATION=true
# LOG_LEVEL=INFO

# ============================================================================
# Testing Environment
# ============================================================================
# BACKEND_TYPE=duckdb
# DUCKDB_DATABASE_PATH=./test_data.duckdb
# OPENAI_API_KEY=sk-test-key-here
# MAX_COST_USD=0.10
# ALLOW_PATIENT_LIST=true
# STRICT_TABLE_VALIDATION=false
# LOG_LEVEL=DEBUG
# DEBUG=true
# MOCK_EXTERNAL_APIS=true
